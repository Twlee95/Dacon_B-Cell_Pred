{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "torch.set_default_dtype(torch.half)\n",
    "torch.set_default_tensor_type(torch.HalfTensor)\n",
    "\n",
    "# # Select visible gpus\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "DEVICE = 'cuda:0'\n",
    "MODEL_NAME = 'Rostlab/prot_t5_xl_half_uniref50-enc'\n",
    "\n",
    "model = T5EncoderModel.from_pretrained(MODEL_NAME, torch_dtype=torch.float16).to(DEVICE)\n",
    "print('model.device:', model.device)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1368, -0.1732, -0.0472,  ...,  0.0454,  0.0054,  0.0166],\n",
       "       device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_T5_emedding(model: T5EncoderModel, tokenizer: T5Tokenizer, seq: str) -> torch.Tensor:\n",
    "    input = tokenizer(' '.join(seq), return_tensors='pt')\n",
    "    for k in input:\n",
    "        input[k] = input[k].to(model.device)\n",
    "    output = model(**input)\n",
    "    return output.last_hidden_state.mean(1).view(-1)\n",
    "\n",
    "# sequence embedding test\n",
    "get_T5_emedding(model, tokenizer, 'ADE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908391a2ea1e4c96be0b1ee5e9d38837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190811 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "epitope_emb = []\n",
    "for epitope_seq in tqdm(df_train.epitope_seq):\n",
    "    epitope_emb.append(get_T5_emedding(model, tokenizer, epitope_seq).cpu().tonumpy())\n",
    "\n",
    "\n",
    "np.save(\"./epitope_emb\",np.array(epitope_emb)) ## 불러올 때 .npy 확장자 넣고 np.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f65463ede8049c988331ea450d79950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_epitope_emb = []\n",
    "for epitope_seq in tqdm(df_test.epitope_seq):\n",
    "    test_epitope_emb.append(get_T5_emedding(model, tokenizer, epitope_seq).cpu().tonumpy())\n",
    "\n",
    "np.save(\"./epitope_emb\",np.array(test_epitope_emb)) ## 불러올 때 .npy 확장자 넣고 np.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('lgai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e05a22552648b8eea438d309e79a17dde508ed650bef67b429a8700e5a5ad60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
